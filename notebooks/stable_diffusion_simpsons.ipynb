{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087cdf1b-3b8f-40b9-bea4-50b539b68aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/spaces/Norod78/sd2-simpsons-blip/blob/main/app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469f2157-1491-4d32-9b40-2e82b18cbeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b60968-ed19-4a35-97ed-0a5d6c794a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, DPMSolverMultistepScheduler\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "model_id = 'Norod78/sd2-simpsons-blip'\n",
    "prefix = None\n",
    "     \n",
    "scheduler = DPMSolverMultistepScheduler(\n",
    "    beta_start=0.00085,\n",
    "    beta_end=0.012,\n",
    "    beta_schedule=\"scaled_linear\",\n",
    "    num_train_timesteps=1000,\n",
    "    trained_betas=None,\n",
    "    #predict_epsilon=True,\n",
    "    prediction_type='epsilon',\n",
    "    thresholding=False,\n",
    "    algorithm_type=\"dpmsolver++\",\n",
    "    solver_type=\"midpoint\",\n",
    "    lower_order_final=True,\n",
    ")\n",
    "\n",
    "use_cuda = False and torch.cuda.is_available()\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "  model_id,\n",
    "  torch_dtype=torch.float16 if use_cuda else torch.float32,\n",
    "  scheduler=scheduler)\n",
    "pipe_i2i = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "  model_id,\n",
    "  torch_dtype=torch.float16 if use_cuda else torch.float32,\n",
    "  scheduler=scheduler)\n",
    "if use_cuda:\n",
    "  pipe = pipe.to(\"cuda\")\n",
    "  pipe.enable_attention_slicing()\n",
    "  pipe_i2i = pipe_i2i.to(\"cuda\")\n",
    "\n",
    "\n",
    "def inference(prompt, guidance, steps, width=512, height=512, seed=0, img=None, strength=0.5, neg_prompt=\"\"):\n",
    "  generator = None\n",
    "  if use_cuda:\n",
    "    generator = torch.Generator('cuda').manual_seed(seed) if seed else None\n",
    "  elif seed:      \n",
    "    generator = torch.Generator()\n",
    "    generator.manual_seed(seed)\n",
    "  try:\n",
    "    if img is not None:\n",
    "      #return img_to_img(prompt, neg_prompt, img, strength, guidance, steps, width, height, generator), None\n",
    "      return img_to_img(prompt, neg_prompt, img, strength, guidance, steps, width, height, generator)\n",
    "    #return txt_to_img(prompt, neg_prompt, guidance, steps, width, height, generator), None\n",
    "    return txt_to_img(prompt, neg_prompt, guidance, steps, width, height, generator)\n",
    "  except Exception as e:\n",
    "    raise\n",
    "    #return None, str(e)\n",
    "\n",
    "def txt_to_img(prompt, neg_prompt, guidance, steps, width, height, generator):\n",
    "    result = pipe(\n",
    "      prompt,\n",
    "      negative_prompt = neg_prompt,\n",
    "      num_inference_steps = int(steps),\n",
    "      guidance_scale = guidance,\n",
    "      width = width,\n",
    "      height = height,\n",
    "      generator = generator)\n",
    "    #return replace_nsfw_images(result)\n",
    "    return result.images[0]\n",
    "\n",
    "def img_to_img(prompt, neg_prompt, img, strength, guidance, steps, width, height, generator):\n",
    "    ratio = min(height / img.height, width / img.width)\n",
    "    img = img.resize((int(img.width * ratio), int(img.height * ratio)), Image.LANCZOS)\n",
    "    result = pipe_i2i(\n",
    "        prompt,\n",
    "        negative_prompt = neg_prompt,\n",
    "        init_image = img,\n",
    "        num_inference_steps = int(steps),\n",
    "        strength = strength,\n",
    "        guidance_scale = guidance,\n",
    "        width = width,\n",
    "        height = height,\n",
    "        generator = generator)\n",
    "    #return replace_nsfw_images(result)\n",
    "    return result.images[0]\n",
    "\n",
    "#def replace_nsfw_images(results):\n",
    "#    for i in range(len(results.images)):\n",
    "#      if 'nsfw_content_detected' in results and results.nsfw_content_detected[i]:\n",
    "#        results.images[i] = Image.open(\"nsfw.png\")\n",
    "#    return results.images[0]\n",
    "\n",
    "def UI():\n",
    "  import gradio as gr\n",
    "  css = \"\"\".main-div div{display:inline-flex;align-items:center;gap:.8rem;font-size:1.75rem}.main-div div h1{font-weight:900;margin-bottom:7px}.main-div p{margin-bottom:10px;font-size:94%}a{text-decoration:underline}.tabs{margin-top:0;margin-bottom:0}#gallery{min-height:20rem}\"\"\"\n",
    "  with gr.Blocks(css=css, analytics_enabled=False) as demo:\n",
    "    gr.HTML(f\"\"\"\n",
    "        <div class=\"main-div\">\n",
    "          <div>\n",
    "            <h1>SDv2 Simpsons</h1>\n",
    "          </div>\n",
    "          <p>\n",
    "           Demo for <a href=\"https://huggingface.co/Norod78/sd2-simpsons-blip\">SD2 Simpsons BLIP</a> Stable Diffusion 2, fine-tuned model.<br>\n",
    "           {\"Add the following tokens to your prompts for the model to work properly: <b>prefix</b>\" if prefix else \"\"}\n",
    "          </p>\n",
    "          Running on {\"<b>GPU ðŸ”¥</b>\" if use_cuda else f\"<b>CPU ðŸ¥¶</b>. For faster inference it is recommended to <b>upgrade to GPU in <a href='https://huggingface.co/spaces/Norod78/sd2-simpsons-blip/settings'>Settings</a></b>\"}<br><br>\n",
    "          <a style=\"display:inline-block\" href=\"https://huggingface.co/spaces/Norod78/sd2-simpsons-blip?duplicate=true\"><img src=\"https://bit.ly/3gLdBN6\" alt=\"Duplicate Space\"></a>\n",
    "        </div>\"\"\")\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=55):\n",
    "          with gr.Group():\n",
    "              with gr.Row():\n",
    "                prompt = gr.Textbox(label=\"Prompt\", show_label=False, max_lines=2,placeholder=\"[your prompt]\").style(container=False)\n",
    "                generate = gr.Button(value=\"Generate\").style(rounded=(False, True, True, False))\n",
    "              image_out = gr.Image(height=512)\n",
    "          error_output = gr.Markdown()\n",
    "        with gr.Column(scale=45):\n",
    "          with gr.Tab(\"Options\"):\n",
    "            with gr.Group():\n",
    "              neg_prompt = gr.Textbox(label=\"Negative prompt\", placeholder=\"What to exclude from the image\")              \n",
    "              with gr.Row():\n",
    "                guidance = gr.Slider(label=\"Guidance scale\", value=7.5, maximum=15)\n",
    "                steps = gr.Slider(label=\"Steps\", value=25, minimum=2, maximum=75, step=1)\n",
    "              with gr.Row():\n",
    "                width = gr.Slider(label=\"Width\", value=512, minimum=64, maximum=1024, step=8)\n",
    "                height = gr.Slider(label=\"Height\", value=512, minimum=64, maximum=1024, step=8)\n",
    "              seed = gr.Slider(0, 2147483647, label='Seed (0 = random)', value=0, step=1)\n",
    "          with gr.Tab(\"Image to image\"):\n",
    "              with gr.Group():\n",
    "                image = gr.Image(label=\"Image\", height=256, tool=\"editor\", type=\"pil\")\n",
    "                strength = gr.Slider(label=\"Transformation strength\", minimum=0, maximum=1, step=0.01, value=0.5)\n",
    "\n",
    "    inputs = [prompt, guidance, steps, width, height, seed, image, strength, neg_prompt]\n",
    "    outputs = [image_out, error_output]\n",
    "    prompt.submit(inference, inputs=inputs, outputs=outputs)\n",
    "    generate.click(inference, inputs=inputs, outputs=outputs)\n",
    "    #gr.HTML(\"\"\"\n",
    "    #    <div style=\"border-top: 1px solid #303030;\">\n",
    "    #      <br>\n",
    "    #      <p>This space was created using <a href=\"https://huggingface.co/spaces/anzorq/sd-space-creator\">SD Space Creator</a>.</p>\n",
    "    #    </div>\"\"\")\n",
    "    demo.queue(concurrency_count=1)\n",
    "    demo.launch(debug=True, share=False, height=768, show_api=False)\n",
    "\n",
    "def manual():\n",
    "    prompt = \"mouse with a blue sign\"\n",
    "    guidance = 7.5 # max 15\n",
    "    steps = 25 # [2, 75]\n",
    "    width = 768\n",
    "    height = 768\n",
    "    seed = 0\n",
    "    image = None\n",
    "    strength = 0.5 # [0, 1]\n",
    "    neg_prompt = \"\"\n",
    "    image_out = inference(prompt, guidance, steps, width, height, seed, image, strength, neg_prompt)\n",
    "    plt.figure()\n",
    "    plt.imshow(image_out)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "#UI()\n",
    "manual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5d046a-f462-4a91-ac2e-210c3b6998e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
