{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2ce84b-3f50-4359-89ee-1d9a545b4584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/qunash/stable-diffusion-2-gui/\n",
    "# https://github.com/qunash/stable-diffusion-2-gui/blob/main/stable_diffusion_2_0.ipynb\n",
    "# https://huggingface.co/stabilityai/stable-diffusion-2-1\n",
    "\n",
    "# Requires:\n",
    "#   accelerate, scipy, triton, ftfy, transformers\n",
    "# pip install --upgrade git+https://github.com/huggingface/diffusers.git@main\n",
    "# pip install --upgrade git+https://github.com/huggingface/transformers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd686d1-376e-4e3b-915c-4a3248a7f60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca780f0-de00-4ce6-8caf-12f63873fa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "import diffusers\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# To test performance delta\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "def inference(inf_mode, prompt, n_images, guidance, steps, width=768, height=768, seed=0, img=None, strength=0.5, neg_prompt=\"\"):\n",
    "    if not seed:\n",
    "        seed = random.randint(0, 2147483647)\n",
    "    print(f\"Seed: {seed}\")\n",
    "    generator = None\n",
    "    if use_cuda:\n",
    "        generator = torch.Generator('cuda').manual_seed(seed) if seed else None\n",
    "    elif seed:      \n",
    "        generator = torch.Generator()\n",
    "        generator.manual_seed(seed)\n",
    "    if inf_mode == 'txt2img':\n",
    "        return txt_to_img(prompt, n_images, neg_prompt, guidance, steps, width, height, generator, seed)\n",
    "    if inf_mode == 'img2img':\n",
    "        if img is None:\n",
    "            raise Exception(\"Image is required for Image to Image mode\")\n",
    "        return img_to_img(prompt, n_images, neg_prompt, img, strength, guidance, steps, width, height, generator, seed)\n",
    "    if inf_mode == 'inpaint':\n",
    "        if img is None:\n",
    "            raise Exception(\"Image is required for Inpainting mode\")\n",
    "        return inpaint(prompt, n_images, neg_prompt, img, guidance, steps, width, height, generator, seed)\n",
    "    if inf_mode == 'upscale4x':\n",
    "        if img is None:\n",
    "            raise Exception(\"Image is required for Upscale mode\")\n",
    "        return upscale(prompt, n_images, neg_prompt, img, guidance, steps, generator)\n",
    "    if inf_mode == 'depth2img':\n",
    "        if img is None:\n",
    "            raise Exception(\"Image is required for Depth to Image mode\")\n",
    "        return depth2img(prompt, n_images, neg_prompt, img, guidance, steps, generator, seed)\n",
    "    raise Exception(\"TODO\")\n",
    "    \n",
    "\n",
    "def txt_to_img(prompt, n_images, neg_prompt, guidance, steps, width, height, generator, seed):\n",
    "    # There's no fp32 revision.\n",
    "    # https://huggingface.co/stabilityai/stable-diffusion-2-1/tree/main\n",
    "    # https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/fp16/model_index.json\n",
    "    pipe = diffusers.StableDiffusionPipeline.from_pretrained(\n",
    "        \"stabilityai/stable-diffusion-2-1\",\n",
    "        revision=\"fp16\",\n",
    "        torch_dtype=torch.float16 if use_cuda else torch.float32)\n",
    "    pipe.scheduler = diffusers.DPMSolverMultistepScheduler.from_pretrained(\n",
    "        \"stabilityai/stable-diffusion-2-1\", subfolder=\"scheduler\")\n",
    "    if use_cuda:\n",
    "        pipe = pipe.to(\"cuda\")\n",
    "        pipe.enable_attention_slicing()\n",
    "    return pipe(\n",
    "        prompt,\n",
    "        num_images_per_prompt=n_images,\n",
    "        negative_prompt=neg_prompt,\n",
    "        num_inference_steps=steps,\n",
    "        guidance_scale=guidance,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        generator=generator).images\n",
    "\n",
    "def img_to_img(prompt, n_images, neg_prompt, img, strength, guidance, steps, width, height, generator, seed):\n",
    "    pipe = diffusers.StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "        model_id,\n",
    "        revision=\"fp16\" if use_cuda else \"fp32\",\n",
    "        torch_dtype=torch.float16 if use_cuda else torch.float32,\n",
    "        scheduler=scheduler)\n",
    "    pipe.scheduler = diffusers.DPMSolverMultistepScheduler.from_pretrained(\n",
    "        pipe.scheduler.config, subfolder=\"scheduler\")\n",
    "    if use_cuda:\n",
    "        pipe.to(\"cuda\")\n",
    "        pipe.enable_attention_slicing()\n",
    "    img = img['image']\n",
    "    ratio = min(height / img.height, width / img.width)\n",
    "    img = img.resize((int(img.width * ratio), int(img.height * ratio)), Image.LANCZOS)\n",
    "    return pipe(\n",
    "        prompt,\n",
    "        num_images_per_prompt=n_images,\n",
    "        negative_prompt=neg_prompt,\n",
    "        image=img,\n",
    "        num_inference_steps=steps,\n",
    "        strength=strength,\n",
    "        guidance_scale=guidance,\n",
    "        # width=width,\n",
    "        # height=height,\n",
    "        generator=generator).images\n",
    "\n",
    "# TODO Currently supports only 512x512 images\n",
    "def inpaint(prompt, n_images, neg_prompt, img, guidance, steps, width, height, generator, seed):\n",
    "    pipe = diffusers.DiffusionPipeline.from_pretrained(\n",
    "        \"stabilityai/stable-diffusion-2-inpainting\",\n",
    "        revision=\"fp16\" if use_cuda else \"fp32\",\n",
    "        torch_dtype=torch.float16 if use_cuda else torch.float32)\n",
    "    pipe.scheduler = diffusers.DPMSolverMultistepScheduler.from_config(\n",
    "        pipe.scheduler.config)\n",
    "    if use_cuda:\n",
    "        pipe.to(\"cuda\")\n",
    "        pipe.enable_attention_slicing()\n",
    "    inp_img = img['image']\n",
    "    mask = img['mask']\n",
    "    inp_img = square_padding(inp_img)\n",
    "    mask = square_padding(mask)\n",
    "    # # ratio = min(height / inp_img.height, width / inp_img.width)\n",
    "    # ratio = min(512 / inp_img.height, 512 / inp_img.width)\n",
    "    # inp_img = inp_img.resize((int(inp_img.width * ratio), int(inp_img.height * ratio)), Image.LANCZOS)\n",
    "    # mask = mask.resize((int(mask.width * ratio), int(mask.height * ratio)), Image.LANCZOS)\n",
    "    return pipe(\n",
    "        prompt,\n",
    "        image=inp_img.resize((512, 512)),\n",
    "        mask_image=mask.resize((512, 512)),\n",
    "        num_images_per_prompt=n_images,\n",
    "        negative_prompt=neg_prompt,\n",
    "        num_inference_steps=steps,\n",
    "        guidance_scale=guidance,\n",
    "        # width=width,\n",
    "        # height=height,\n",
    "        generator=generator).images\n",
    "\n",
    "def depth2img(prompt, n_images, neg_prompt, img, guidance, steps, generator, seed):\n",
    "    pipe = diffusers.StableDiffusionDepth2ImgPipeline.from_pretrained(\n",
    "        \"stabilityai/stable-diffusion-2-depth\",\n",
    "        revision=\"fp16\" if use_cuda else \"fp32\",\n",
    "        torch_dtype=torch.float16 if use_cuda else torch.float32)\n",
    "    pipe.scheduler = diffusers.DPMSolverMultistepScheduler.from_config(\n",
    "        pipe.scheduler.config)\n",
    "    if use_cuda:\n",
    "        pipe.to(\"cuda\")\n",
    "        pipe.enable_attention_slicing()\n",
    "    return pipe(\n",
    "        prompt,\n",
    "        num_images_per_prompt=n_images,\n",
    "        negative_prompt=neg_prompt,\n",
    "        image=img['image'],\n",
    "        num_inference_steps=steps,\n",
    "        guidance_scale=guidance,\n",
    "        # width=width,\n",
    "        # height=height,\n",
    "        generator=generator).images\n",
    "\n",
    "def square_padding(img):\n",
    "    width, height = img.size\n",
    "    if width == height:\n",
    "        return img\n",
    "    new_size = max(width, height)\n",
    "    new_img = Image.new('RGB', (new_size, new_size), (0, 0, 0, 255))\n",
    "    new_img.paste(img, ((new_size - width) // 2, (new_size - height) // 2))\n",
    "    return new_img\n",
    "\n",
    "def upscale(prompt, n_images, neg_prompt, img, guidance, steps, generator):\n",
    "    pipe = diffusers.StableDiffusionUpscalePipeline.from_pretrained(\n",
    "        \"stabilityai/stable-diffusion-x4-upscaler\",\n",
    "        revision=\"fp16\" if use_cuda else \"fp32\",\n",
    "        torch_dtype=torch.float16 if use_cuda else torch.float32)\n",
    "    # pipe.scheduler = diffusers.DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "    if use_cuda:\n",
    "        pipe.to(\"cuda\")\n",
    "        pipe.enable_attention_slicing()\n",
    "    return upscale_tiling(pipe, prompt, neg_prompt, img[\"image\"], guidance, steps, generator)\n",
    "    # return pipe(\n",
    "    #     prompt,\n",
    "    #     image=img[\"image\"],\n",
    "    #     num_inference_steps=steps,\n",
    "    #     guidance_scale=guidance,\n",
    "    #     negative_prompt=neg_prompt,\n",
    "    #     num_images_per_prompt=n_images,\n",
    "    #     generator=generator).images[0]\n",
    "\n",
    "def upscale_tiling(pipe, prompt, neg_prompt, img, guidance, steps, generator):\n",
    "    width, height = img.size\n",
    "\n",
    "    # calculate the padding needed to make the image dimensions a multiple of 128\n",
    "    padding_x = 128 - (width % 128) if width % 128 != 0 else 0\n",
    "    padding_y = 128 - (height % 128) if height % 128 != 0 else 0\n",
    "\n",
    "    # create a white image of the right size to be used as padding\n",
    "    padding_img = Image.new('RGB', (padding_x, padding_y), color=(255, 255, 255, 0))\n",
    "\n",
    "    # paste the padding image onto the original image to add the padding\n",
    "    img.paste(padding_img, (width, height))\n",
    "\n",
    "    # update the image dimensions to include the padding\n",
    "    width += padding_x\n",
    "    height += padding_y\n",
    "    \n",
    "    if width > 128 or height > 128:\n",
    "        num_tiles_x = int(width / 128)\n",
    "        num_tiles_y = int(height / 128)\n",
    "        upscaled_img = Image.new('RGB', (img.size[0] * 4, img.size[1] * 4))\n",
    "        for x in range(num_tiles_x):\n",
    "            for y in range(num_tiles_y):\n",
    "                print(f\"Upscaling tile {x * num_tiles_y + y + 1}/{num_tiles_x * num_tiles_y}\")\n",
    "                tile = img.crop((x * 128, y * 128, (x + 1) * 128, (y + 1) * 128))\n",
    "                upscaled_tile = pipe(\n",
    "                    prompt=\"\",\n",
    "                    image=tile,\n",
    "                    num_inference_steps=steps,\n",
    "                    guidance_scale=guidance,\n",
    "                    # negative_prompt=neg_prompt,\n",
    "                    generator=generator).images[0]\n",
    "                upscaled_img.paste(upscaled_tile, (x * upscaled_tile.size[0], y * upscaled_tile.size[1]))\n",
    "        return [upscaled_img]\n",
    "    return pipe(\n",
    "        prompt=prompt,\n",
    "        image=img,\n",
    "        num_inference_steps=steps,\n",
    "        guidance_scale=guidance,\n",
    "        negative_prompt = neg_prompt,\n",
    "        generator=generator).images\n",
    "\n",
    "def run(prompt):\n",
    "    print(\"Processing:\")\n",
    "    n_images = 1 # number of images\n",
    "    inf_mode = \"txt2img\" # img2img, inpaint, upscale4x, depth2img\n",
    "    neg_prompt = \"\"\n",
    "    guidance = 7.5 # max = 15\n",
    "    steps = 25 # [2, 100]\n",
    "    width = 768  # [64, 1024] step=8\n",
    "    height = 768 # [64, 1024] step=8\n",
    "    seed = 10 # random\n",
    "    strength = 0.5 # [0, 1]\n",
    "    image = None\n",
    "    gallery = inference(inf_mode, prompt, n_images, guidance, steps, width, height, seed, image, strength, neg_prompt)\n",
    "    plt.figure()\n",
    "    plt.imshow(gallery[0])\n",
    "    plt.axis(\"off\")\n",
    "    return gallery[0]\n",
    "\n",
    "run(\"a squirrel cat hybrid\").save(\"out/squicat3.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
